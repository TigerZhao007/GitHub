# -*- coding: utf-8 -*-
"""
Created on Thu Nov 30 15:19:02 2017

@author: Administrator
"""

import re
import requests
import urllib.request
import pandas as pd
from bs4 import BeautifulSoup

## 链家网连接
url = 'https://nanjing.anjuke.com/community/o4/'
url1 = 'https://nanjing.anjuke.com/community/view/193894?from=Filter_1&hfilter=filterlist'
url2 = 'https://nanjing.anjuke.com/community/view/397657?from=Filter_1&hfilter=filterlist'
headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'
      		}

## 爬取列表连接
def get_link(url,headers):
    req = requests.get(url=url,headers=headers)
    resp = req.text
    soup = BeautifulSoup(resp, 'lxml')
    dat1 = soup.find_all('div',attrs={'class':'li-info'})
#    return dat1
    dat2 = re.findall(r'href="/community/view/(.+?)/jiedu/"',str(dat1))
    return dat2

## 爬取网页内部内容
def get_dat(url,headers):
    req = requests.get(url=url,headers=headers)
    resp = req.text
    soup = BeautifulSoup(resp, 'lxml')    

    dat1 = soup.find_all('dl',attrs={'class':'basic-parms-mod'})
    wylx = re.findall(r'物业类型：</dt><dd>(.+?)</dd>',str(dat1))[0]
    wyf  = re.findall(r'物业费：</dt><dd class="other-dd">(.+?)</dd>',str(dat1))[0]
    area = re.findall(r'总建面积：</dt><dd>(.+?)</dd>',str(dat1))[0]
    buildtime = re.findall(r'建造年代：</dt><dd>(.+?)</dd>',str(dat1))[0]
    rate = re.findall(r'</dt><dd>(.+?)</dd>',str(dat1))[3]
    lh = re.findall(r'绿化率：</dt><dd class="other-dd">(.+?)</dd>',str(dat1))[0]
    kf = re.findall(r'</dt><dd class="dd-column">(.+?)</dd>',str(dat1))[0]
    wygs = re.findall(r'物业公司：</dt><dd class="dd-column">(.+?)</dd>',str(dat1))[0]

    dat2 = soup.find_all('div',attrs={'class':'comm-title'})
    name = re.findall(r'title="(.+?)"><i class="iconfont">',str(dat2))[0]
    address = re.findall(r'<span class="sub-hd">(.+?)</span>',str(dat2))[0]

    dat = [name,address,area,buildtime,rate,lh,wyf,wylx,wygs,kf]
    return dat

## 综合爬取函数
def write_dat(area,n):
   print('正在读取%s页的文本' % (area))
   f1 = open(r'C:\\Users\\Administrator\\Desktop\\%s.csv'%(area),'a')
   headers = {
      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36',
      }
   for i in range(n):
       url = 'https://nanjing.anjuke.com/community/%s/o6-p'%(area) + str(i)
       print('正在读取%s页的文本' % (i+1))
       df0 = get_link(url,headers)
       for df in df0:
           url1 = 'https://nanjing.anjuke.com/community/view/%s?from=Filter_1&hfilter=filterlist'%(df)
           print('正在读取%s的文本' % (url1))
           df1 = get_dat(url1,headers)
           f1.writelines(str(df1)+'\n')
           print('---------------------------------------成功保存文本')
   f1.close()

def main(): 
    area_total = ['guloua','jianye','qinhuai','xuanwub','yuhuatai','qixia','jiangninga','pukou','liuhe','lishuia','gaochun']
    n_total    = ['3','3','3','3','3','3','3','3','3','3','3']
    for k in range(0,len(n_total)): 
        area = area_total[k]
        n    = int(n_total[k])
        write_dat(area,n)

## 执行主函数
if __name__ == '__main__':
	main()
