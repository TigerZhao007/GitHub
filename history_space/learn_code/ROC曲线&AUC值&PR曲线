# ROC曲线和AUC值
ROC（Receiver Operating Characteristic）曲线和AUC常被用来评价一个二值分类器（binary classifier）的优劣。
http://blog.csdn.net/ice110956/article/details/20288239
http://blog.csdn.net/zdy0_2004/article/details/44948511

## ROC曲线

*ROC曲线的横坐标为false positive rate（FPR），纵坐标为true positive rate（TPR）。
1、roc曲线：接收者操作特征(receiveroperating characteristic),roc曲线上每个点反映着对同一信号刺激的感受性。
横轴：负正类率(false postive rate FPR)特异度，划分实例中所有负例占所有负例的比例；(1-Specificity)
纵轴：真正类率(true postive rate TPR)灵敏度，Sensitivity(正类覆盖率)
2针对一个二分类问题，将实例分成正类(postive)或者负类(negative)。但是实际中分类时，会出现四种情况.
(1)若一个实例是正类并且被预测为正类，即为真正类(True Postive TP)
(2)若一个实例是正类，但是被预测成为负类，即为假负类(False Negative FN)
(3)若一个实例是负类，但是被预测成为正类，即为假正类(False Postive FP)
(4)若一个实例是负类，但是被预测成为负类，即为真负类(True Negative TN)
TP:正确的肯定数目
FN:漏报，没有找到正确匹配的数目
FP:误报，没有的匹配不正确
TN:正确拒绝的非匹配数目
*对于0,1两类分类问题,一些分类器得到的结果往往不是0,1这样的标签,如神经网络,得到诸如0.5,0,8这样的分类结果。
这时,我们人为取一个阈值,比如0.4,那么小于0.4的为0类,大于等于0.4的为1类,可以得到一个分类结果。
同样,这个阈值我们可以取0.1,0.2等等。取不同的阈值,得到的最后的分类情况也就不同。
http://img.blog.csdn.net/20140302141730359
蓝色表示原始为负类分类得到的统计图,红色为正类得到的统计图。那么我们取一条直线,直线左边分为负类,右边分为正,这条直线也就是我们所取的阈值。
阈值不同,可以得到不同的结果,但是由分类器决定的统计图始终是不变的。这时候就需要一个独立于阈值,只与分类器有关的评价指标,来衡量特定分类器的好坏。
还有在类不平衡的情况下,如正样本90个,负样本10个,直接把所有样本分类为正样本,得到识别率为90%。但这显然是没有意义的。
如上就是ROC曲线的动机。
*关于两类分类问题,原始类为positive,negative,分类后的类别为p,n。排列组合后得到4种结果,如下:
http://img.blog.csdn.net/20140302141735812
于是我们得到四个指标,分别为真阳,伪阳;伪阴,真阴。
ROC空间将伪阳性率（FPR）定义为 X 轴，真阳性率（TPR）定义为 Y 轴。这两个值由上面四个值计算得到,公式如下:
TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率。TPR=TP/(TP+FN)
FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率。FPR=FP/(FP+TN)
放在具体领域来理解上述两个指标。如在医学诊断中,判断有病的样本。那么尽量把有病的揪出来是主要任务,也就是第一个指标TPR,要越高越好。
而把没病的样本误诊为有病的,也就是第二个指标FPR,要越低越好。
不难发现,这两个指标之间是相互制约的。如果某个医生对于有病的症状比较敏感,稍微的小症状都判断为有病,那么他的第一个指标应该会很高,
但是第二个指标也就相应地变高。最极端的情况下,他把所有的样本都看做有病,那么第一个指标达到1,第二个指标也为1。
我们以FPR为横轴,TPR为纵轴,得到如下ROC空间。

## AUC值
AUC值为ROC曲线所覆盖的区域面积,显然,AUC越大,分类器分类效果越好。
AUC = 1，是完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。
0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。
AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。
AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。
*AUC的物理意义
假设分类器的输出是样本属于正类的socre（置信度），则AUC的物理意义为，任取一对（正、负）样本，正样本的score大于负样本的score的概率。
*计算AUC:
第一种方法:AUC为ROC曲线下的面积,那我们直接计算面积可得。面积为一个个小的梯形面积之和。计算的精度与阈值的精度有关。
第二种方法:根据AUC的物理意义,我们计算正样本score大于负样本的score的概率。取N*M(N为正样本数,M为负样本数)个二元组,比较score,最后得到AUC。时间复杂度为O(N*M)。
第三种方法:与第二种方法相似,直接计算正样本score大于负样本的概率。我们首先把所有样本按照score排序,依次用rank表示他们,如最大score的样本,rank=n(n=N+M),其次为n-1。
那么对于正样本中rank最大的样本,rank_max,有M-1个其他正样本比他score小,那么就有(rank_max-1)-(M-1)个负样本比他score小。
其次为(rank_second-1)-(M-2)。最后我们得到正样本大于负样本的概率为     ，时间复杂度为O(N+M)。

## PR曲线
对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例（TP），假反例（FN），假正例（FP），真反例（TN）
查准率P和查全率R分别定义为：
P=TP/(TP+FP)
R=TP/(TP+FN)
查准率关心的是”预测出正例的正确率”即从正反例子中挑选出正例的问题。 
查全率关心的是”预测出正例的保证性”即从正例中挑选出正例的问题。

这两者是一对矛盾的度量，查准率可以认为是”宁缺毋滥”，适合对准确率要求高的应用，例如商品推荐，网页检索等。
查全率可以认为是”宁错杀一百，不放过1个”，适合类似于检查走私、逃犯信息等。

若一个学习器的P-R曲线被另一个学习器完全”包住”，则后者的性能优于前者。
当存在交叉时，可以计算曲线围住面积，但比较麻烦，平衡点（查准率=查全率，BEP）是一种度量方式。

3.偏差和方差
泛化误差可以分解为偏差、方差与噪声之和.
偏差度量了学习算法的期望预测和真实结果偏离程度。
方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。
噪声可以认为数据自身的波动性，表达了目前任何学习算法所能达到泛化误差的下限。
偏差大说明欠拟合，方差大说明过拟合。
