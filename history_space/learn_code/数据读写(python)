# python数据读取介绍
read_table(filepath_or_buffer[, sep, …])              	读取普通分隔的数据
read_csv(filepath_or_buffer[, sep, …])	                  读取csv格式的数据
read_excel(io[, sheetname, header, …])	                  读取excel格式的数据
read_json([path_or_buf, orient, typ, dtype, …])	            读取json格式的数据
read_html(io[, match, flavor, header, …])   	            读取html格式的 数据
read_sql(sql, con[, index_col, …])	                        读取数据库中的数据

## csv格式文件读取
import pandas as pd
#-*- coding=utf-8 -*-
df1 = pd.read_csv('texiao_zong.csv',encoding="gb18030")     # 解决表内有中文，报错问题
df2 = pd.read_csv('texiao_zong.csv',encoding="gb2312")      # 解决表内有中文，报错问题
df3 = pd.read_csv(path,encoding = 'gbk', engine='python')   # 解决表名，表内有中文，报错问题

## excel格式文件读取
import pandas as pd
path = 'F:/pspace/texiao_zong.xlsx'
df4 = pd.read_excel(path,sheetname='Sheet1',encoding = 'gbk')
所有参数含义介绍：
pd.read_excel(io, sheetname=0, header=0, skiprows=None, skip_footer=0, 
      index_col=None, names=None, parse_cols=None, parse_dates=False, 
      date_parser=None, na_values=None, thousands=None, convert_float=True, 
      has_index_names=None, converters=None, dtype=None, true_values=None, 
      false_values=None, engine=None, squeeze=False, **kwds)
 该函数主要的参数为io、sheetname、header、names、encoding。
 io:excel文件，可以是文件路径、文件网址、file-like对象、xlrd workbook;
 sheetname:返回指定的sheet，参数可以是字符串（sheet名）、整型（sheet索引）、
           list（元素为字符串和整型，返回字典{'key':'sheet'}）、none（返回字典，全部sheet）;
 header:指定数据表的表头，参数可以是int、list of ints，即为索引行数为表头;
 names:返回指定name的列，参数为array-like对象。
 encoding:关键字参数，指定以何种编码读取。
 该函数返回pandas中的DataFrame或dict of DataFrame对象，利用DataFrame的相关操作即可读取相应的数据。
 
## json格式文件读取
import pandas as pd
pd.read_json('example.json')

## sql数据库读取
windows+R>cmd>pip install pymysql3
import pymysql
import pandas as pd
conn=pymysql.connect(host='127.0.0.1',user='root',passwd='123456',
                     db='world',port=3306,charset='utf8')
data_sql=pd.read_sql("select * from city limit 10",conn)

## txt格式文件读取
import pandas as pd

## dat格式文件读取
import pandas as pd
path1 = 'C:/Users/SDK/Desktop/users.dat'
unames = ['id','gender','age','occupation','zip']
users = pd.read_table(path1, sep='::',header=None, names=unames)

## html网页读取
????????????????????????????????????????????????????????????????
import pandas as pd
data = pd.DataFrame()
url_list = ['http://www.espn.com/nba/salaries/_/seasontype/4']
for i in range(2, 13):
    url = 'http://www.espn.com/nba/salaries/_/page/%s/seasontype/4' % i
    url_list.append(url)
for url in url_list:
    data = data.append(pd.read_html(url), ignore_index=True)
data = data[[x.startswith('$') for x in data[3]]]
data.to_csv('NAB_salaries.csv',header=['RK','NAME','TEAM','SALARY'], index=False)

# python数据写入介绍
## csv格式文件写入
import pandas as pd
df.to_csv('output.csv')

## excel格式文件写入
import pandas as pd
1. df.to_excel('output.xlsx','Sheet1')
2. writer = pd.ExcelWriter('output.xlsx')
   df.to_excel(writer,'Sheet1')
   writer.save()
所有参数含义介绍：
DataFrame.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, 
      columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, 
      engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None)
该函数主要参数为:excel_writer。
excel_writer:写入的目标excel文件，可以是文件路径、ExcelWriter对象;
sheet_name:被写入的sheet名称，string类型，默认为'sheet1';
na_rep:缺失值表示，string类型;
header:是否写表头信息，布尔或list of string类型，默认为True;
index:是否写行号，布尔类型，默认为True;
encoding:指定写入编码，string类型。

## json格式文件写入
import pandas as pd
df.to_json('output.json')

## txt格式文件写入






